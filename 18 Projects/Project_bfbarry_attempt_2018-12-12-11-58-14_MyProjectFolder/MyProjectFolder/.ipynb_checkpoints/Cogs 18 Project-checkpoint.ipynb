{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compression in Python – A Tutorial\n",
    "\n",
    "\n",
    "### What is Compression?\n",
    "\n",
    "Compression is a method used to shrink the size of files in order to save storage space on a device.  When downloading content from the internet, we often encounter files with the extension .zip or .rar.  These are instances of files that have been compressed.  Upon opening, they create the 'original', accessible file.\n",
    "\n",
    "   There are diverse and complex schools of thought on how to approach compression, ranging from information theory to statistics.  And as we experience the age of big data, research in this field is in an incessant pursuit for more efficient compression methdos.  In general, the algorithms that make compression possible rely on some rather intuitive mathematical rules.  Text compression essentially remove redundancy from a file by removing redundant repeating characters (or patterns of characters), and keeping track of these in a dictionary.  For image compression, the same idea applies except instead of characters it manipulates pixels and their colors.  \n",
    "\n",
    "### Data Compression Modules from the Python Standard Library (https://docs.python.org/3/library/archiving.html)\n",
    "\n",
    "   Python offers several algorithms for this topic.  This tutorial will focus on the most of these methods.  \n",
    "   \n",
    "   \n",
    "   \n",
    "This project has been uploaded to github (username brianatUCSD): https://github.com/brianatUCSD/Cogs-18-Final-Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## — How to use zlib: Functions —\n",
    "\n",
    "This section will explain how to use zlib.  Zlib is a lossless algorithm that can compress as well as decompress files.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "• We start by importing the zlib object\n",
    "\n",
    "• For the purpose of this project, we also import sys to indicate the size of files to show how sucessful the compression worked.  This will be shown in the function code.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we can compress a file of interest using the following.  Parameters are explained in the comments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zlib.compress(data, level=-1)\n",
    "\n",
    "    #data is the data being compressed\n",
    "    #level is the amount of compression desired, from 0-9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To decompress a file we use: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zlib.decompress(data, wbits=MAX_WBITS, bufsize=DEF_BUF_SIZE)\n",
    "\n",
    "    #data is what is being decompressed\n",
    "    #wbits controls the window size (max 15)\n",
    "    #bufsize is used as the initial size of the output buffer (where the buffer is the location in memory where data is temporarily held)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`compressobj` creates a compressed object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zlib.compressobj(level=-1, method=DEFLATED, wbits=MAX_WBITS, memLevel=DEF_MEM_LEVEL, strategy=Z_DEFAULT_STRATEGY[, zdict])\n",
    "\n",
    "    # A level of 1 is fastest\n",
    "    # 'DEFLATED' is the only compression method available\n",
    "    # wbits controls the window size (max 15)\n",
    "    # memLevel is the amount of memory used for compression (1-9)\n",
    "    # Strategy tunes the compression                              \n",
    "    # zdict is the compression dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`decompressobj` creates a decompresed object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zlib.decompressobj(wbits=MAX_WBITS[, zdict])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## — How to use gzip: Functions —\n",
    "\n",
    "Gzip is a type of compression that builds off of the zlib library.\n",
    "\n",
    "Gzip thus has similar functions like compress and decompress. However for decompress the only input is `data`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "• To return a gzip-compressed file object, use gzip.open"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gzip.open(filename, mode='rb', compresslevel=9, encoding=None, errors=None, newline=None)\n",
    "    #mode has multiple options for either binary mode or text mode\n",
    "    #compresslevel takes the same values from 0 - 9\n",
    "    # encoding, errors, and newline are usually empty for binary mode."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## — How to use zipfile: Functions —\n",
    "\n",
    "The .ZIP is one of the most common type of compression/archive file formats available.  It differs from the previous implementations in that it can store entire folders easily as opposed to individual text or image files. \n",
    "\n",
    "There are many functions used for more advanced applications with data structures, so this with focus on a surface level implication that most users would do.  This will just demonstrate how to create a ZIP file directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'sample.zip'\n",
    "zip_file = ZipFile(file_name, \"w\")\n",
    "zip_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## — How to use gzip: Functions —\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploration and Research Application 1: Run Length Encoding\n",
    "\n",
    "I would now like to explore how to create a very basic algorithm that approaches compression using the definition explained in the introduction.  Run Length Encoding is a type of lossless compression that looks for sequences of repeated characters and then reduces them to avoid redundancy.  \n",
    "\n",
    "#### First sample code\n",
    "The first code does not require you to import anything.  It uses recursion to encode input as whatever character followed by the number of iterations of that character.\n",
    "\n",
    "The following code was found on https://gist.github.com/hltbra/4117933\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(text):\n",
    "    if not text: #insures input\n",
    "        return \"\"\n",
    "    else:\n",
    "        last_char = text[0] \n",
    "        max_index = len(text)\n",
    "        i = 1\n",
    "        while i < max_index and last_char == text[i]:\n",
    "            i += 1\n",
    "        return last_char + str(i) + encode(text[i:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Second sample code\n",
    "\n",
    "This code takes advantage of the itertools library, which consists of functions that help make looping more efficient.  This compression also looks at characters repeated more than 4 times.\n",
    "\n",
    "This particular instance of itertools uses groupby(), which terminates on the shortest input sequence.  This allows us to differentiate when a new group of characters occurs.\n",
    "\n",
    "This particular usage was found on a thread on Stackexchange. (https://stackoverflow.com/questions/18948382/run-length-encoding-in-python)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import groupby\n",
    "\n",
    "def runLengthEncode(text):\n",
    "    result_list = []\n",
    "\n",
    "    for k,i in groupby(text):  # k and i are variables to loop through the keys and the groups in the input\n",
    "        run = list(i)\n",
    "        if(len(run) > 4): #check if it exceeds 4\n",
    "            result_list.append(\"/{:02}{}\".format(len(run), k))  #append new characters\n",
    "        else:\n",
    "            res.extend(run) #extend appends any elements in the list, rather the actual list\n",
    "\n",
    "    return \"\".join(result_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploration and Research Application 2: Fractal Compression\n",
    "\n",
    "Fractal compression is especially interesting because it looks for areas of self similarity in an image.  Because of this, it is ideal for natural images (such as landscapes) and combines well with machine learning.  Fractal compression is not ideal for real time applications, as encoding is computationally expensive.  The decoding however is not.  \n",
    "\n",
    "The following implementation of fractal image compression was made by user pvigier on Github (https://github.com/pvigier/fractal-image-compression). It essentially applies fractal transformations on an image, requiring heavy usage of Python's math library and matplot, a plotting library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from scipy import ndimage\n",
    "from scipy import optimize\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "# Manipulate channels\n",
    "\n",
    "def get_greyscale_image(img):\n",
    "    return np.mean(img[:,:,:2], 2)\n",
    "\n",
    "def extract_rgb(img):\n",
    "    return img[:,:,0], img[:,:,1], img[:,:,2]\n",
    "\n",
    "def assemble_rbg(img_r, img_g, img_b):\n",
    "    shape = (img_r.shape[0], img_r.shape[1], 1)\n",
    "    return np.concatenate((np.reshape(img_r, shape), np.reshape(img_g, shape), \n",
    "        np.reshape(img_b, shape)), axis=2)\n",
    "\n",
    "# Transformations\n",
    "\n",
    "def reduce(img, factor):\n",
    "    result = np.zeros((img.shape[0] // factor, img.shape[1] // factor))\n",
    "    for i in range(result.shape[0]):\n",
    "        for j in range(result.shape[1]):\n",
    "            result[i,j] = np.mean(img[i*factor:(i+1)*factor,j*factor:(j+1)*factor])\n",
    "    return result\n",
    "\n",
    "def rotate(img, angle):\n",
    "    return ndimage.rotate(img, angle, reshape=False)\n",
    "\n",
    "def flip(img, direction):\n",
    "    return img[::direction,:]\n",
    "\n",
    "def apply_transformation(img, direction, angle, contrast=1.0, brightness=0.0):\n",
    "    return contrast*rotate(flip(img, direction), angle) + brightness\n",
    "\n",
    "# Contrast and brightness\n",
    "\n",
    "def find_contrast_and_brightness1(D, S):\n",
    "    # Fix the contrast and only fit the brightness\n",
    "    contrast = 0.75\n",
    "    brightness = (np.sum(D - contrast*S)) / D.size\n",
    "    return contrast, brightness \n",
    "\n",
    "def find_contrast_and_brightness2(D, S):\n",
    "    # Fit the contrast and the brightness\n",
    "    A = np.concatenate((np.ones((S.size, 1)), np.reshape(S, (S.size, 1))), axis=1)\n",
    "    b = np.reshape(D, (D.size,))\n",
    "    x, _, _, _ = np.linalg.lstsq(A, b)\n",
    "    #x = optimize.lsq_linear(A, b, [(-np.inf, -2.0), (np.inf, 2.0)]).x\n",
    "    return x[1], x[0]\n",
    "\n",
    "# Compression for greyscale images\n",
    "\n",
    "def generate_all_transformed_blocks(img, source_size, destination_size, step):\n",
    "    factor = source_size // destination_size\n",
    "    transformed_blocks = []\n",
    "    for k in range((img.shape[0] - source_size) // step + 1):\n",
    "        for l in range((img.shape[1] - source_size) // step + 1):\n",
    "            # Extract the source block and reduce it to the shape of a destination block\n",
    "            S = reduce(img[k*step:k*step+source_size,l*step:l*step+source_size], factor)\n",
    "            # Generate all possible transformed blocks\n",
    "            for direction, angle in candidates:\n",
    "                transformed_blocks.append((k, l, direction, angle, apply_transformation(S, direction, angle)))\n",
    "    return transformed_blocks\n",
    "\n",
    "def compress(img, source_size, destination_size, step):\n",
    "    transformations = []\n",
    "    transformed_blocks = generate_all_transformed_blocks(img, source_size, destination_size, step)\n",
    "    for i in range(img.shape[0] // destination_size):\n",
    "        transformations.append([])\n",
    "        for j in range(img.shape[1] // destination_size):\n",
    "            print(i, j)\n",
    "            transformations[i].append(None)\n",
    "            min_d = float('inf')\n",
    "            # Extract the destination block\n",
    "            D = img[i*destination_size:(i+1)*destination_size,j*destination_size:(j+1)*destination_size]\n",
    "            # Test all possible transformations and take the best one\n",
    "            for k, l, direction, angle, S in transformed_blocks:\n",
    "                contrast, brightness = find_contrast_and_brightness2(D, S)\n",
    "                S = contrast*S + brightness\n",
    "                d = np.sum(np.square(D - S))\n",
    "                if d < min_d:\n",
    "                    min_d = d\n",
    "                    transformations[i][j] = (k, l, direction, angle, contrast, brightness)\n",
    "    return transformations\n",
    "\n",
    "def decompress(transformations, source_size, destination_size, step, nb_iter=8):\n",
    "    factor = source_size // destination_size\n",
    "    height = len(transformations) * destination_size\n",
    "    width = len(transformations[0]) * destination_size\n",
    "    iterations = [np.random.randint(0, 256, (height, width))]\n",
    "    cur_img = np.zeros((height, width))\n",
    "    for i_iter in range(nb_iter):\n",
    "        print(i_iter)\n",
    "        for i in range(len(transformations)):\n",
    "            for j in range(len(transformations[i])):\n",
    "                # Apply transform\n",
    "                k, l, flip, angle, contrast, brightness = transformations[i][j]\n",
    "                S = reduce(iterations[-1][k*step:k*step+source_size,l*step:l*step+source_size], factor)\n",
    "                D = apply_transformation(S, flip, angle, contrast, brightness)\n",
    "                cur_img[i*destination_size:(i+1)*destination_size,j*destination_size:(j+1)*destination_size] = D\n",
    "        iterations.append(cur_img)\n",
    "        cur_img = np.zeros((height, width))\n",
    "    return iterations\n",
    "\n",
    "# Compression for color images\n",
    "\n",
    "def reduce_rgb(img, factor):\n",
    "    img_r, img_g, img_b = extract_rgb(img)\n",
    "    img_r = reduce(img_r, factor)\n",
    "    img_g = reduce(img_g, factor)\n",
    "    img_b = reduce(img_b, factor)\n",
    "    return assemble_rbg(img_r, img_g, img_b)\n",
    "\n",
    "def compress_rgb(img, source_size, destination_size, step):\n",
    "    img_r, img_g, img_b = extract_rgb(img)\n",
    "    return [compress(img_r, source_size, destination_size, step), \\\n",
    "        compress(img_g, source_size, destination_size, step), \\\n",
    "        compress(img_b, source_size, destination_size, step)]\n",
    "\n",
    "def decompress_rgb(transformations, source_size, destination_size, step, nb_iter=8):\n",
    "    img_r = decompress(transformations[0], source_size, destination_size, step, nb_iter)[-1]\n",
    "    img_g = decompress(transformations[1], source_size, destination_size, step, nb_iter)[-1]\n",
    "    img_b = decompress(transformations[2], source_size, destination_size, step, nb_iter)[-1]\n",
    "    return assemble_rbg(img_r, img_g, img_b)\n",
    "\n",
    "# Plot\n",
    "\n",
    "def plot_iterations(iterations, target=None):\n",
    "    # Configure plot\n",
    "    plt.figure()\n",
    "    nb_row = math.ceil(np.sqrt(len(iterations)))\n",
    "    nb_cols = nb_row\n",
    "    # Plot\n",
    "    for i, img in enumerate(iterations):\n",
    "        plt.subplot(nb_row, nb_cols, i+1)\n",
    "        plt.imshow(img, cmap='gray', vmin=0, vmax=255, interpolation='none')\n",
    "        if target is None:\n",
    "            plt.title(str(i))\n",
    "        else:\n",
    "            # Display the RMSE\n",
    "            plt.title(str(i) + ' (' + '{0:.2f}'.format(np.sqrt(np.mean(np.square(target - img)))) + ')')\n",
    "        frame = plt.gca()\n",
    "        frame.axes.get_xaxis().set_visible(False)\n",
    "        frame.axes.get_yaxis().set_visible(False)\n",
    "    plt.tight_layout()\n",
    "\n",
    "# Parameters\n",
    "\n",
    "directions = [1, -1]\n",
    "angles = [0, 90, 180, 270]\n",
    "candidates = list(zip(directions, angles))\n",
    "\n",
    "# Tests\n",
    "\n",
    "def test_greyscale():\n",
    "    img = mpimg.imread('monkey.gif')\n",
    "    img = get_greyscale_image(img)\n",
    "    img = reduce(img, 4)\n",
    "    plt.figure()\n",
    "    plt.imshow(img, cmap='gray', interpolation='none')\n",
    "    transformations = compress(img, 8, 4, 8)\n",
    "    iterations = decompress(transformations, 8, 4, 8)\n",
    "    plot_iterations(iterations, img)\n",
    "    plt.show()\n",
    "\n",
    "def test_rgb():\n",
    "    img = mpimg.imread('lena.gif')\n",
    "    img = reduce_rgb(img, 8)\n",
    "    transformations = compress_rgb(img, 8, 4, 8)\n",
    "    retrieved_img = decompress_rgb(transformations, 8, 4, 8)\n",
    "    plt.figure()\n",
    "    plt.subplot(121)\n",
    "    plt.imshow(np.array(img).astype(np.uint8), interpolation='none')\n",
    "    plt.subplot(122)\n",
    "    plt.imshow(retrieved_img.astype(np.uint8), interpolation='none')\n",
    "    plt.show()\n",
    "                    \n",
    "if __name__ == '__main__':\n",
    "    test_greyscale()\n",
    "    #test_rgb()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Functions\n",
    "\n",
    "`functions.py` in the my_module folder will compress a file.  The program will ask for a file name as input, followed by the level of desired compression.  It will then print out the compressed version of the file.  A sample file is given in the directory, called 'notes.txt'.\n",
    "\n",
    "It will also have functions that use the exploratory run length encoding algorithm.\n",
    "\n",
    "The functions have onto them added a size comparison output to show the efficiency of the compression.\n",
    "\n",
    "The scripts work, but must be used in the same directory as the functions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
